{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Google_Colaboratory_Install_and_Test_Spark.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"P645BMsabeJO","colab_type":"text"},"cell_type":"markdown","source":["**Install JDK, Spark and Findspark.**"]},{"metadata":{"id":"MJjcQVyaaWb_","colab_type":"code","outputId":"66ea2708-80fd-4848-c756-aa7f47c13c3a","executionInfo":{"status":"ok","timestamp":1549969812526,"user_tz":-240,"elapsed":27699,"user":{"displayName":"Daniel Chirita","photoUrl":"","userId":"03327998290993072627"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["%%shell \n","apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","rm spark*.tgz*\n","wget -q https://www-eu.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n","tar xf spark-2.4.0-bin-hadoop2.7.tgz\n","pip install -q findspark"],"execution_count":1,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'spark*.tgz*': No such file or directory\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"lNZv8gEIZerR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"587e4061-bbd5-47da-c7ba-70bca1cdf277","executionInfo":{"status":"ok","timestamp":1549969815208,"user_tz":-240,"elapsed":30371,"user":{"displayName":"Daniel Chirita","photoUrl":"","userId":"03327998290993072627"}}},"cell_type":"code","source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["sample_data  spark-2.4.0-bin-hadoop2.7\tspark-2.4.0-bin-hadoop2.7.tgz\n"],"name":"stdout"}]},{"metadata":{"id":"zTeowpWIbqlW","colab_type":"text"},"cell_type":"markdown","source":["**Test Pyspark.**"]},{"metadata":{"id":"Jkum44INbGvh","colab_type":"code","colab":{}},"cell_type":"code","source":["# SET PATHS\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n","\n","# INITIALIZE FINDSPARK\n","import findspark\n","findspark.init()\n","\n","# CREATE CONTEXT\n","import pyspark\n","sc = pyspark.SparkContext(appName=\"Estimate PI\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UPU0iuJYesuM","colab_type":"code","outputId":"6517aa44-4ba8-46b9-a0e1-19833373b97e","executionInfo":{"status":"ok","timestamp":1549969841491,"user_tz":-240,"elapsed":3386,"user":{"displayName":"Daniel Chirita","photoUrl":"","userId":"03327998290993072627"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# Estimate PI\n","import numpy as np\n","\n","def inside(p):\n","    x, y = np.random.random(), np.random.random()\n","    return x*x + y*y < 1\n","\n","N = 1000000\n","count = sc.parallelize(range(N)).filter(inside).count()\n","print(\"PI is approximately \", 4*count/N)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["PI is approximately  3.145184\n"],"name":"stdout"}]},{"metadata":{"id":"3NmzeSnYZs9q","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}